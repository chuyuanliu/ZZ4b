0 >> Epoch <<   Data Set |  Loss %(mj, tt, zz, zh, hh) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6466 (37, 10, 24, 28, 16) | 0.937 | 1.076 | 89.93 | 86.09 |--------------------|
0             Validation | 0.6469 (37, 10, 24, 28, 16) | 0.944 | 1.083 | 89.82 | 86.13 |#####################| ^ (0.4%, 7.93, 2.0, 0%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (1008 batches)
0 >>  2/20 <<   Training | 0.6203 (30, 11, 27, 31, 17) | 1.021 | 1.166 | 90.52 | 86.94 |-----------------------------|
0             Validation | 0.6202 (30, 11, 27, 31, 17) | 1.026 | 1.170 | 90.39 | 87.06 |##############################| ^ (0.4%, 9.91, 2.3, 0%) 
0 >>  3/20 <<   Training | 0.6128 (34, 10, 27, 29, 15) | 1.047 | 1.197 | 90.45 | 87.25 |--------------------------------|
0             Validation | 0.6129 (34, 10, 27, 29, 15) | 1.056 | 1.208 | 90.44 | 87.34 |#################################| ^ (0.4%, 8.85, 1.9, 1%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (504 batches)
0 >>  4/20 <<   Training | 0.6093 (38, 12, 21, 29, 16) | 1.038 | 1.187 | 90.96 | 87.31 |---------------------------------|
0             Validation | 0.6102 (38, 12, 21, 28, 16) | 1.044 | 1.194 | 90.83 | 87.38 |#################################| ^ (0.3%, 8.78, 1.8, 1%) 
0 >>  5/20 <<   Training | 0.6043 (34, 10, 25, 30, 16) | 1.075 | 1.228 | 90.83 | 87.43 |----------------------------------|
0             Validation | 0.6047 (34, 10, 25, 30, 16) | 1.082 | 1.233 | 90.79 | 87.51 |###################################| ^ (0.4%, 9.64, 1.8, 1%) 
0 >>  6/20 <<   Training | 0.6130 (39, 10, 21, 29, 16) | 1.020 | 1.167 | 90.70 | 87.35 |---------------------------------|
0             Validation | 0.6135 (39, 10, 21, 28, 16) | 1.012 | 1.158 | 90.57 | 87.46 |##################################| ^ (0.4%, 10.40, 1.9, 1%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (252 batches)
0 >>  7/20 <<   Training | 0.6013 (31, 11, 27, 30, 16) | 1.100 | 1.256 | 90.90 | 87.58 |-----------------------------------|
0             Validation | 0.6023 (31, 11, 27, 30, 16) | 1.091 | 1.250 | 90.78 | 87.61 |####################################| ^ (0.3%, 9.90, 2.2, 0%) 
0 >>  8/20 <<   Training | 0.5985 (35, 10, 24, 29, 17) | 1.093 | 1.247 | 91.32 | 87.62 |------------------------------------|
0             Validation | 0.5996 (35, 10, 24, 28, 17) | 1.105 | 1.262 | 91.13 | 87.67 |####################################| ^ (0.3%, 9.29, 1.5, 6%) 
0 >>  9/20 <<   Training | 0.5986 (32, 11, 25, 31, 17) | 1.112 | 1.269 | 91.12 | 87.64 |------------------------------------|
0             Validation | 0.5996 (32, 11, 25, 30, 17) | 1.122 | 1.279 | 91.02 | 87.69 |####################################| ^ (0.3%, 9.50, 1.6, 3%) 
0 >> 10/20 <<   Training | 0.5986 (32, 11, 26, 31, 16) | 1.105 | 1.260 | 91.00 | 87.65 |------------------------------------|
0             Validation | 0.5996 (31, 11, 26, 30, 16) | 1.113 | 1.270 | 90.93 | 87.70 |####################################| ^ (0.3%, 9.68, 1.6, 3%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (126 batches)
0 >> 11/20 <<   Training | 0.5972 (39,  9, 25, 27, 15) | 1.073 | 1.225 | 91.18 | 87.70 |-------------------------------------|
0             Validation | 0.5990 (39,  9, 25, 27, 15) | 1.066 | 1.216 | 91.04 | 87.74 |#####################################| ^ (0.3%, 10.04, 1.4, 10%) 
0 >> 12/20 <<   Training | 0.5973 (35, 10, 23, 32, 16) | 1.079 | 1.233 | 91.32 | 87.61 |------------------------------------|
0             Validation | 0.5995 (34, 10, 23, 31, 16) | 1.082 | 1.235 | 91.12 | 87.60 |###################################| ^ (0.3%, 10.43, 1.8, 1%) 
0 >> 13/20 <<   Training | 0.5973 (37, 11, 23, 27, 17) | 1.070 | 1.222 | 91.37 | 87.69 |------------------------------------|
0             Validation | 0.5990 (37, 11, 23, 27, 17) | 1.075 | 1.227 | 91.19 | 87.72 |#####################################| ^ (0.3%, 9.73, 1.9, 1%) 
0 >> 14/20 <<   Training | 0.5968 (32, 10, 27, 29, 16) | 1.108 | 1.265 | 91.03 | 87.68 |------------------------------------|
0             Validation | 0.5985 (32, 10, 28, 29, 16) | 1.103 | 1.258 | 90.85 | 87.74 |#####################################| ^ (0.3%, 10.33, 1.9, 0%) 
0 >> 15/20 <<   Training | 0.5954 (38, 10, 23, 28, 16) | 1.099 | 1.254 | 91.35 | 87.73 |-------------------------------------|
0             Validation | 0.5967 (38, 10, 23, 28, 16) | 1.107 | 1.263 | 91.21 | 87.76 |#####################################| ^ (0.3%, 9.25, 1.4, 9%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.5930 (36, 10, 24, 29, 16) | 1.103 | 1.258 | 91.29 | 87.77 |-------------------------------------|
0             Validation | 0.5952 (36, 10, 25, 29, 16) | 1.104 | 1.259 | 91.13 | 87.76 |#####################################| ^ (0.2%, 9.84, 1.9, 1%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.5916 (36, 10, 24, 29, 16) | 1.108 | 1.264 | 91.39 | 87.83 |--------------------------------------|
0             Validation | 0.5937 (36, 10, 24, 29, 16) | 1.120 | 1.278 | 91.22 | 87.84 |######################################| ^ (0.2%, 10.00, 1.3, 11%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.5914 (36, 10, 24, 29, 16) | 1.110 | 1.267 | 91.37 | 87.83 |--------------------------------------|
0             Validation | 0.5935 (35, 10, 25, 29, 16) | 1.122 | 1.280 | 91.20 | 87.84 |######################################| ^ (0.2%, 10.03, 1.4, 10%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.5914 (35, 10, 24, 29, 16) | 1.118 | 1.276 | 91.36 | 87.83 |--------------------------------------|
0             Validation | 0.5935 (35, 10, 25, 29, 16) | 1.126 | 1.285 | 91.19 | 87.84 |######################################| ^ (0.2%, 10.05, 1.4, 8%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.5914 (35, 10, 24, 29, 16) | 1.115 | 1.273 | 91.36 | 87.83 |--------------------------------------|
0             Validation | 0.5935 (35, 10, 25, 29, 16) | 1.130 | 1.289 | 91.20 | 87.84 |######################################| ^ (0.2%, 10.04, 1.4, 8%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_MA_HCR+attention_8_np1061_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
0 >> Epoch <<   Data Set |  Loss %(mj, tt, zz, zh, hh) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6763 (43, 14, 20, 26, 13) | 0.892 | 1.041 | 89.59 | 85.94 |-------------------|
0             Validation | 0.6739 (43, 14, 19, 26, 13) | 0.882 | 1.032 | 89.69 | 86.00 |####################| ^ (0.4%, 10.41, 1.0, 45%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (961 batches)
0 >>  2/20 <<   Training | 0.6238 (37, 10, 23, 29, 15) | 1.058 | 1.229 | 90.71 | 86.90 |----------------------------|
0             Validation | 0.6226 (37, 10, 23, 29, 15) | 1.054 | 1.228 | 90.87 | 86.93 |#############################| ^ (0.2%, 12.08, 1.6, 2%) 
0 >>  3/20 <<   Training | 0.6245 (38, 12, 22, 27, 15) | 1.039 | 1.202 | 90.57 | 86.83 |----------------------------|
0             Validation | 0.6225 (38, 12, 22, 27, 15) | 1.029 | 1.195 | 90.82 | 86.87 |############################| ^ (0.3%, 13.80, 1.5, 4%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (480 batches)
0 >>  4/20 <<   Training | 0.6145 (32, 11, 29, 29, 15) | 1.110 | 1.285 | 90.38 | 87.13 |-------------------------------|
0             Validation | 0.6145 (32, 11, 28, 29, 15) | 1.115 | 1.297 | 90.54 | 87.12 |###############################| ^ (0.3%, 12.60, 2.6, 0%) 
0 >>  5/20 <<   Training | 0.6235 (31,  9, 30, 30, 15) | 1.078 | 1.251 | 89.53 | 86.95 |-----------------------------|
0             Validation | 0.6234 (31,  9, 29, 30, 15) | 1.073 | 1.249 | 89.62 | 86.95 |#############################| ^ (0.2%, 14.57, 1.7, 2%) 
0 >>  6/20 <<   Training | 0.6116 (38, 10, 25, 29, 14) | 1.065 | 1.236 | 90.64 | 87.09 |------------------------------|
0             Validation | 0.6117 (38, 10, 24, 29, 14) | 1.039 | 1.212 | 90.68 | 87.11 |###############################| ^ (0.2%, 14.36, 1.5, 5%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (240 batches)
0 >>  7/20 <<   Training | 0.6034 (36, 11, 25, 29, 14) | 1.100 | 1.275 | 90.92 | 87.44 |----------------------------------|
0             Validation | 0.6037 (36, 11, 25, 30, 14) | 1.108 | 1.288 | 90.90 | 87.44 |##################################| ^ (0.2%, 12.46, 1.8, 1%) 
0 >>  8/20 <<   Training | 0.6096 (32,  8, 28, 32, 15) | 1.130 | 1.307 | 90.56 | 87.39 |---------------------------------|
0             Validation | 0.6103 (32,  8, 28, 32, 15) | 1.109 | 1.288 | 90.58 | 87.37 |#################################| ^ (0.2%, 12.82, 1.4, 7%) 
0 >>  9/20 <<   Training | 0.6036 (33, 10, 24, 32, 16) | 1.128 | 1.301 | 90.94 | 87.39 |---------------------------------|
0             Validation | 0.6043 (33, 10, 24, 32, 16) | 1.127 | 1.307 | 90.92 | 87.36 |#################################| ^ (0.3%, 12.18, 1.7, 2%) 
0 >> 10/20 <<   Training | 0.6042 (38, 10, 21, 30, 16) | 1.058 | 1.225 | 91.24 | 87.35 |---------------------------------|
0             Validation | 0.6046 (38, 10, 21, 30, 16) | 1.066 | 1.238 | 91.30 | 87.35 |#################################| ^ (0.3%, 13.53, 1.1, 26%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (120 batches)
0 >> 11/20 <<   Training | 0.5975 (37, 11, 24, 29, 15) | 1.132 | 1.308 | 91.21 | 87.61 |------------------------------------|
0             Validation | 0.5983 (37, 11, 24, 29, 15) | 1.117 | 1.296 | 91.22 | 87.58 |###################################| ^ (0.2%, 12.76, 1.6, 4%) 
0 >> 12/20 <<   Training | 0.6019 (30, 11, 26, 33, 16) | 1.171 | 1.352 | 91.08 | 87.52 |-----------------------------------|
0             Validation | 0.6026 (30, 11, 26, 33, 16) | 1.163 | 1.347 | 91.10 | 87.49 |##################################| ^ (0.3%, 13.37, 0.9, 58%) 
0 >> 13/20 <<   Training | 0.5985 (33, 10, 27, 31, 15) | 1.151 | 1.331 | 91.02 | 87.56 |-----------------------------------|
0             Validation | 0.5997 (33, 10, 27, 31, 15) | 1.139 | 1.323 | 90.97 | 87.52 |###################################| ^ (0.2%, 14.02, 1.7, 2%) 
0 >> 14/20 <<   Training | 0.6018 (33, 10, 28, 30, 15) | 1.130 | 1.306 | 90.58 | 87.52 |-----------------------------------|
0             Validation | 0.6030 (33, 10, 28, 30, 15) | 1.110 | 1.289 | 90.50 | 87.49 |##################################| ^ (0.2%, 14.28, 1.9, 1%) 
0 >> 15/20 <<   Training | 0.5975 (35, 10, 25, 30, 15) | 1.133 | 1.309 | 91.05 | 87.60 |-----------------------------------|
0             Validation | 0.5986 (35, 10, 25, 30, 15) | 1.156 | 1.344 | 90.99 | 87.56 |###################################| ^ (0.2%, 14.27, 1.3, 15%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.5949 (35, 10, 25, 30, 14) | 1.148 | 1.326 | 91.23 | 87.65 |------------------------------------|
0             Validation | 0.5961 (35, 10, 25, 30, 14) | 1.150 | 1.335 | 91.16 | 87.62 |####################################| ^ (0.2%, 13.84, 1.2, 19%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.5938 (36, 10, 25, 30, 15) | 1.157 | 1.336 | 91.28 | 87.70 |-------------------------------------|
0             Validation | 0.5950 (35, 10, 25, 30, 15) | 1.146 | 1.330 | 91.23 | 87.66 |####################################| ^ (0.2%, 13.64, 1.5, 6%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.5937 (35, 10, 25, 30, 15) | 1.156 | 1.336 | 91.26 | 87.71 |-------------------------------------|
0             Validation | 0.5948 (35, 10, 25, 30, 15) | 1.149 | 1.333 | 91.20 | 87.67 |####################################| ^ (0.2%, 13.59, 1.4, 8%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.5936 (36, 10, 25, 30, 15) | 1.154 | 1.333 | 91.27 | 87.71 |-------------------------------------|
0             Validation | 0.5948 (35, 10, 25, 30, 15) | 1.149 | 1.333 | 91.22 | 87.67 |####################################| ^ (0.2%, 13.59, 1.4, 8%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.5936 (36, 10, 25, 30, 15) | 1.155 | 1.334 | 91.27 | 87.71 |-------------------------------------|
0             Validation | 0.5948 (35, 10, 25, 30, 15) | 1.149 | 1.333 | 91.21 | 87.67 |####################################| ^ (0.2%, 13.61, 1.5, 6%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_MA_HCR+attention_8_np1061_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
0 >> Epoch <<   Data Set |  Loss %(mj, tt, zz, zh, hh) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6540 (40, 11, 21, 27, 14) | 0.970 | 1.136 | 89.65 | 86.05 |--------------------|
0             Validation | 0.6522 (40, 11, 21, 27, 14) | 0.969 | 1.130 | 89.82 | 86.12 |#####################| ^ (0.3%, 11.36, 1.3, 12%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (936 batches)
0 >> Epoch <<   Data Set |  Loss %(mj, tt, zz, zh, hh) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6540 (40, 11, 21, 27, 14) | 0.970 | 1.136 | 89.65 | 86.05 |--------------------|
0             Validation | 0.6522 (40, 11, 21, 27, 14) | 0.969 | 1.130 | 89.82 | 86.12 |#####################| ^ (0.3%, 11.36, 1.3, 12%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (936 batches)
0 >>  2/20 <<   Training | 0.6232 (38, 10, 24, 27, 14) | 1.048 | 1.224 | 90.59 | 86.78 |---------------------------|
0             Validation | 0.6225 (38, 10, 24, 27, 14) | 1.039 | 1.210 | 90.36 | 86.85 |############################| ^ (0.4%, 11.37, 1.4, 9%) 
0 >>  3/20 <<   Training | 0.6204 (35,  9, 26, 28, 15) | 1.091 | 1.272 | 90.09 | 86.83 |----------------------------|
0             Validation | 0.6196 (35,  9, 26, 28, 15) | 1.093 | 1.271 | 89.74 | 86.94 |#############################| ^ (0.4%, 12.02, 1.3, 14%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (468 batches)
0 >>  4/20 <<   Training | 0.6124 (32, 10, 26, 31, 15) | 1.127 | 1.312 | 90.71 | 87.12 |-------------------------------|
0             Validation | 0.6120 (32, 10, 26, 31, 15) | 1.119 | 1.297 | 90.53 | 87.19 |###############################| ^ (0.4%, 11.67, 0.7, 82%) 
0 >>  5/20 <<   Training | 0.6183 (32,  8, 26, 32, 15) | 1.133 | 1.317 | 90.85 | 86.84 |----------------------------|
0             Validation | 0.6175 (32,  8, 26, 32, 15) | 1.144 | 1.324 | 90.70 | 86.92 |#############################| ^ (0.5%, 10.38, 1.3, 14%) 
0 >>  6/20 <<   Training | 0.6097 (32, 10, 25, 30, 16) | 1.143 | 1.328 | 90.81 | 87.24 |--------------------------------|
0             Validation | 0.6096 (32, 10, 25, 30, 16) | 1.161 | 1.345 | 90.53 | 87.32 |#################################| ^ (0.4%, 10.10, 1.3, 13%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (234 batches)
0 >>  7/20 <<   Training | 0.6042 (33, 11, 25, 30, 15) | 1.156 | 1.347 | 91.13 | 87.33 |---------------------------------|
0             Validation | 0.6035 (33, 11, 25, 30, 15) | 1.165 | 1.349 | 90.97 | 87.43 |##################################| ^ (0.4%, 11.59, 0.8, 61%) 
0 >>  8/20 <<   Training | 0.6054 (36, 10, 23, 28, 15) | 1.120 | 1.302 | 91.37 | 87.30 |---------------------------------|
0             Validation | 0.6050 (36, 10, 23, 28, 15) | 1.123 | 1.302 | 91.14 | 87.40 |##################################| ^ (0.4%, 11.17, 0.9, 55%) 
0 >>  9/20 <<   Training | 0.6048 (36, 10, 23, 29, 15) | 1.122 | 1.303 | 91.13 | 87.30 |---------------------------------|
0             Validation | 0.6045 (36, 10, 24, 29, 15) | 1.145 | 1.325 | 90.90 | 87.38 |#################################| ^ (0.3%, 11.44, 1.3, 16%) 
0 >> 10/20 <<   Training | 0.6047 (34, 11, 23, 29, 16) | 1.130 | 1.315 | 91.19 | 87.29 |--------------------------------|
0             Validation | 0.6046 (34, 11, 23, 29, 16) | 1.122 | 1.300 | 90.94 | 87.38 |#################################| ^ (0.4%, 11.71, 1.1, 29%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (117 batches)
0 >> 11/20 <<   Training | 0.6041 (35, 10, 23, 30, 15) | 1.122 | 1.303 | 91.29 | 87.30 |--------------------------------|
0             Validation | 0.6034 (35, 10, 23, 30, 15) | 1.118 | 1.293 | 91.15 | 87.39 |#################################| ^ (0.3%, 11.57, 0.9, 57%) 
0 >> 12/20 <<   Training | 0.6058 (29, 11, 27, 31, 16) | 1.168 | 1.356 | 91.10 | 87.37 |---------------------------------|
0             Validation | 0.6050 (29, 11, 27, 31, 16) | 1.173 | 1.356 | 90.83 | 87.47 |##################################| ^ (0.4%, 11.67, 1.2, 18%) 
0 >> 13/20 <<   Training | 0.6056 (41, 10, 22, 27, 14) | 1.118 | 1.302 | 91.42 | 87.39 |---------------------------------|
0             Validation | 0.6053 (41, 10, 22, 27, 14) | 1.128 | 1.305 | 91.21 | 87.48 |##################################| ^ (0.3%, 10.81, 0.8, 67%) 
0 >> 14/20 <<   Training | 0.6021 (35,  9, 23, 31, 15) | 1.143 | 1.327 | 91.29 | 87.41 |----------------------------------|
0             Validation | 0.6018 (35,  9, 23, 31, 15) | 1.140 | 1.319 | 91.12 | 87.48 |##################################| ^ (0.3%, 11.17, 1.1, 24%) 
0 >> 15/20 <<   Training | 0.6028 (38, 10, 24, 27, 13) | 1.120 | 1.300 | 91.33 | 87.41 |----------------------------------|
0             Validation | 0.6020 (38, 10, 24, 27, 13) | 1.129 | 1.308 | 91.12 | 87.50 |##################################| ^ (0.4%, 11.28, 1.0, 37%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.5996 (34, 10, 26, 29, 15) | 1.182 | 1.373 | 91.29 | 87.49 |----------------------------------|
0             Validation | 0.5990 (34, 10, 26, 29, 15) | 1.185 | 1.370 | 91.06 | 87.59 |###################################| ^ (0.4%, 11.57, 0.7, 80%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.5987 (34, 10, 25, 29, 15) | 1.179 | 1.368 | 91.37 | 87.50 |-----------------------------------|
0             Validation | 0.5984 (34, 10, 25, 29, 15) | 1.186 | 1.373 | 91.16 | 87.59 |###################################| ^ (0.3%, 11.54, 0.7, 77%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.5984 (35, 10, 24, 29, 15) | 1.173 | 1.362 | 91.39 | 87.52 |-----------------------------------|
0             Validation | 0.5981 (35, 10, 24, 29, 15) | 1.175 | 1.360 | 91.19 | 87.60 |###################################| ^ (0.3%, 11.52, 0.8, 66%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.5984 (35, 10, 24, 29, 15) | 1.174 | 1.363 | 91.40 | 87.52 |-----------------------------------|
0             Validation | 0.5980 (35, 10, 24, 29, 15) | 1.174 | 1.359 | 91.19 | 87.60 |####################################| ^ (0.3%, 11.54, 0.8, 64%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.5984 (35, 10, 24, 29, 15) | 1.174 | 1.363 | 91.40 | 87.52 |-----------------------------------|
0             Validation | 0.5980 (35, 10, 24, 29, 15) | 1.174 | 1.358 | 91.20 | 87.60 |####################################| ^ (0.3%, 11.54, 0.8, 62%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_MA_HCR+attention_8_np1061_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
0 >> Epoch <<   Data Set |  Loss %(mj, tt, zz, zh, hh) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6507 (44,  9, 22, 24, 13) | 1.099 | 1.293 | 90.34 | 85.94 |-------------------|
0             Validation | 0.6483 (45,  9, 21, 24, 13) | 1.112 | 1.313 | 90.41 | 86.03 |####################| ^ (0.3%, 7.61, 0.9, 54%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (930 batches)
0 >>  2/20 <<   Training | 0.6158 (33, 10, 28, 28, 14) | 1.324 | 1.540 | 90.65 | 87.01 |------------------------------|
0 >> Epoch <<   Data Set |  Loss %(mj, tt, zz, zh, hh) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >> Epoch <<   Data Set |  Loss %(mj, tt, zz, zh, hh) | σ     | σ(SR) | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.6495 (40, 12, 18, 34, 18) | 0.884 | 1.036 | 90.22 | 86.04 |--------------------|
0             Validation | 0.6481 (40, 12, 18, 34, 18) | 0.896 | 1.046 | 90.00 | 86.15 |#####################| ^ (0.3%, 9.61, 1.3, 12%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (936 batches)
0 >>  2/20 <<   Training | 0.6403 (39, 11, 17, 34, 21) | 0.945 | 1.111 | 90.19 | 86.22 |----------------------|
0             Validation | 0.6389 (39, 11, 17, 34, 21) | 0.944 | 1.102 | 90.22 | 86.32 |#######################| ^ (0.3%, 8.50, 1.6, 4%) 
0 >>  3/20 <<   Training | 0.6180 (39, 11, 18, 34, 20) | 0.977 | 1.138 | 90.55 | 86.71 |---------------------------|
0             Validation | 0.6165 (39, 11, 18, 34, 20) | 1.001 | 1.162 | 90.57 | 86.78 |###########################| ^ (0.3%, 10.78, 1.3, 15%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (468 batches)
0 >>  4/20 <<   Training | 0.6040 (37,  9, 20, 34, 21) | 1.079 | 1.254 | 90.80 | 87.07 |------------------------------|
0             Validation | 0.6013 (37,  9, 20, 35, 21) | 1.104 | 1.281 | 90.79 | 87.21 |################################| ^ (0.4%, 10.49, 0.8, 61%) 
0 >>  5/20 <<   Training | 0.6145 (37, 11, 17, 35, 22) | 1.044 | 1.213 | 90.82 | 87.03 |------------------------------|
0             Validation | 0.6128 (37, 11, 17, 35, 22) | 1.059 | 1.230 | 90.85 | 87.14 |###############################| ^ (0.3%, 9.64, 1.1, 30%) 
0 >>  6/20 <<   Training | 0.6066 (43,  9, 18, 30, 21) | 1.032 | 1.201 | 91.16 | 87.15 |-------------------------------|
0             Validation | 0.6041 (43,  9, 17, 31, 21) | 1.056 | 1.226 | 91.06 | 87.31 |#################################| ^ (0.4%, 10.82, 1.6, 3%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (234 batches)
0 >>  7/20 <<   Training | 0.6014 (38, 10, 19, 33, 22) | 1.094 | 1.274 | 91.15 | 87.22 |--------------------------------|
0             Validation | 0.5993 (38, 10, 19, 33, 22) | 1.104 | 1.284 | 91.06 | 87.36 |#################################| ^ (0.4%, 9.86, 1.3, 14%) 
0 >>  8/20 <<   Training | 0.5981 (40,  9, 20, 33, 18) | 1.040 | 1.211 | 90.64 | 87.20 |--------------------------------|
0             Validation | 0.5955 (40,  9, 20, 33, 18) | 1.056 | 1.228 | 90.64 | 87.35 |#################################| ^ (0.4%, 9.55, 0.9, 56%) 
0 >>  9/20 <<   Training | 0.6026 (45,  9, 18, 31, 19) | 1.013 | 1.180 | 91.03 | 87.26 |--------------------------------|
0             Validation | 0.6002 (45,  9, 18, 31, 19) | 1.032 | 1.199 | 91.02 | 87.40 |##################################| ^ (0.4%, 8.91, 1.4, 8%) 
0 >> 10/20 <<   Training | 0.6048 (44,  9, 17, 32, 19) | 1.042 | 1.215 | 91.28 | 87.29 |--------------------------------|
0             Validation | 0.6023 (44,  9, 16, 32, 19) | 1.055 | 1.228 | 91.25 | 87.44 |##################################| ^ (0.4%, 10.09, 1.3, 11%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (117 batches)
0 >> 11/20 <<   Training | 0.6031 (35, 11, 18, 36, 21) | 1.101 | 1.283 | 91.06 | 87.22 |--------------------------------|
0             Validation | 0.6012 (35, 11, 18, 36, 21) | 1.120 | 1.299 | 91.05 | 87.31 |#################################| ^ (0.3%, 10.03, 0.9, 56%) 
0 >> 12/20 <<   Training | 0.6008 (44, 10, 18, 32, 18) | 1.025 | 1.193 | 91.12 | 87.33 |---------------------------------|
0             Validation | 0.5982 (44, 10, 18, 32, 18) | 1.046 | 1.213 | 91.08 | 87.45 |##################################| ^ (0.4%, 10.36, 0.7, 79%) 
0 >> 13/20 <<   Training | 0.5972 (37, 10, 19, 35, 20) | 1.104 | 1.283 | 91.11 | 87.38 |---------------------------------|
0             Validation | 0.5950 (37, 10, 18, 35, 20) | 1.125 | 1.303 | 91.06 | 87.50 |###################################| ^ (0.4%, 9.79, 0.9, 57%) 
0 >> 14/20 <<   Training | 0.6089 (41, 10, 16, 34, 21) | 1.064 | 1.238 | 91.01 | 87.25 |--------------------------------|
0             Validation | 0.6071 (41,  9, 16, 34, 21) | 1.096 | 1.274 | 90.99 | 87.35 |#################################| ^ (0.3%, 9.31, 0.8, 65%) 
0 >> 15/20 <<   Training | 0.5958 (42, 10, 19, 32, 19) | 1.073 | 1.247 | 91.18 | 87.32 |---------------------------------|
0             Validation | 0.5933 (42, 10, 19, 32, 19) | 1.089 | 1.264 | 91.13 | 87.44 |##################################| ^ (0.4%, 9.73, 1.0, 44%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.5952 (40,  9, 18, 33, 21) | 1.105 | 1.284 | 91.29 | 87.46 |----------------------------------|
0             Validation | 0.5928 (40,  9, 18, 33, 21) | 1.116 | 1.294 | 91.22 | 87.59 |###################################| ^ (0.4%, 10.13, 1.0, 36%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.5937 (40,  9, 19, 33, 20) | 1.092 | 1.269 | 91.24 | 87.45 |----------------------------------|
0             Validation | 0.5913 (40,  9, 18, 33, 20) | 1.102 | 1.278 | 91.18 | 87.57 |###################################| ^ (0.4%, 10.16, 1.5, 6%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.5947 (41,  9, 18, 33, 20) | 1.094 | 1.271 | 91.27 | 87.47 |----------------------------------|
0             Validation | 0.5923 (41,  9, 18, 33, 20) | 1.108 | 1.285 | 91.22 | 87.59 |###################################| ^ (0.4%, 10.09, 1.3, 15%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.5943 (40,  9, 18, 33, 20) | 1.094 | 1.272 | 91.27 | 87.46 |----------------------------------|
0             Validation | 0.5919 (40,  9, 18, 33, 20) | 1.109 | 1.285 | 91.22 | 87.58 |###################################| ^ (0.4%, 10.09, 1.1, 28%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.5943 (40,  9, 18, 33, 20) | 1.093 | 1.270 | 91.27 | 87.46 |----------------------------------|
0             Validation | 0.5919 (40,  9, 18, 33, 20) | 1.108 | 1.284 | 91.22 | 87.58 |###################################| ^ (0.4%, 10.08, 1.0, 38%) * ZZ4b/nTupleAnalysis/pytorchModels/SvB_MA_HCR+attention_8_np1061_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
