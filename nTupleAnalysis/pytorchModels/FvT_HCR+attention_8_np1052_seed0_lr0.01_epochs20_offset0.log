0 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
0 >>  1/20 <<   Training | 0.8852 (24, 32,  7, 20) | 0.946 | 10.107 | 83.48 | 67.82 |----------------------------|
0             Validation | 0.8870 (24, 32,  7, 20) | 0.945 | 4.419 | 83.38 | 67.33 |#######################| ^ (2.7%, 2.58, 1.3, 16%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (1337 batches)
0 >>  2/20 <<   Training | 0.8760 (25, 32,  7, 19) | 0.990 | 5.183 | 83.93 | 68.28 |--------------------------------|
0             Validation | 0.8783 (25, 32,  7, 19) | 0.988 | 3.665 | 83.84 | 67.85 |############################| ^ (2.3%, 3.82, 1.6, 4%) 
0 >>  3/20 <<   Training | 0.8751 (25, 29,  7, 21) | 0.979 | 9.122 | 84.30 | 68.88 |--------------------------------------|
0             Validation | 0.8768 (25, 29,  7, 21) | 0.978 | 6.314 | 84.21 | 68.59 |###################################| ^ (1.5%, 3.82, 2.2, 0%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (668 batches)
0 >>  4/20 <<   Training | 0.8671 (27, 32,  7, 18) | 1.067 | 5.176 | 84.87 | 68.67 |------------------------------------|
0             Validation | 0.8695 (27, 32,  7, 18) | 1.065 | 3.088 | 84.76 | 68.25 |################################| ^ (2.3%, 5.75, 1.3, 12%) 
0 >>  5/20 <<   Training | 0.8716 (26, 28,  7, 21) | 1.050 | 4.596 | 84.84 | 68.75 |-------------------------------------|
0             Validation | 0.8737 (26, 28,  7, 21) | 1.048 | 3.330 | 84.75 | 68.37 |#################################| ^ (2.1%, 5.47, 1.7, 2%) 
0 >>  6/20 <<   Training | 0.8665 (26, 31,  7, 19) | 1.013 | 2.822 | 84.76 | 68.82 |--------------------------------------|
0             Validation | 0.8692 (26, 31,  7, 19) | 1.011 | 2.360 | 84.65 | 68.34 |#################################| ^ (2.6%, 4.67, 1.2, 20%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (334 batches)
0 >>  7/20 <<   Training | 0.8640 (26, 30,  7, 20) | 1.017 | 1.912 | 85.08 | 69.38 |-------------------------------------------|
0             Validation | 0.8665 (26, 30,  7, 20) | 1.016 | 1.595 | 84.98 | 68.96 |#######################################| ^ (2.2%, 4.32, 1.3, 11%) 
0 >>  8/20 <<   Training | 0.8636 (25, 31,  7, 20) | 0.959 | 3.748 | 85.09 | 69.85 |------------------------------------------------|
0             Validation | 0.8663 (25, 31,  7, 20) | 0.958 | 3.075 | 84.97 | 69.41 |############################################| ^ (2.2%, 4.13, 2.3, 0%) 
0 >>  9/20 <<   Training | 0.8627 (25, 31,  7, 19) | 1.008 | 2.473 | 85.10 | 69.95 |-------------------------------------------------|
0             Validation | 0.8653 (25, 31,  7, 19) | 1.006 | 1.929 | 84.98 | 69.48 |############################################| ^ (2.4%, 4.13, 1.3, 13%) 
0 >> 10/20 <<   Training | 0.8632 (26, 31,  7, 19) | 1.040 | 3.371 | 85.09 | 70.03 |--------------------------------------------------|
0             Validation | 0.8659 (26, 31,  7, 19) | 1.039 | 2.164 | 84.98 | 69.53 |#############################################| ^ (2.5%, 3.47, 2.4, 0%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (167 batches)
0 >> 11/20 <<   Training | 0.8638 (27, 31,  7, 18) | 1.099 | 9.639 | 85.21 | 70.06 |--------------------------------------------------|
0             Validation | 0.8665 (27, 31,  7, 18) | 1.097 | 4.579 | 85.10 | 69.58 |#############################################| ^ (2.4%, 3.76, 1.5, 5%) 
0 >> 12/20 <<   Training | 0.8624 (25, 33,  7, 19) | 0.927 | 10.382 | 85.16 | 69.99 |-------------------------------------------------|
0             Validation | 0.8653 (25, 33,  7, 19) | 0.926 | 7.034 | 85.05 | 69.53 |#############################################| ^ (2.3%, 4.07, 2.0, 0%) 
0 >> 13/20 <<   Training | 0.8629 (24, 34,  7, 18) | 0.916 | 8.813 | 85.15 | 69.89 |------------------------------------------------|
0             Validation | 0.8659 (24, 34,  7, 18) | 0.914 | 5.620 | 85.03 | 69.37 |###########################################| ^ (2.6%, 3.88, 1.7, 2%) 
0 >> 14/20 <<   Training | 0.8623 (25, 31,  7, 19) | 1.004 | 0.780 | 85.12 | 69.74 |-----------------------------------------------|
0             Validation | 0.8653 (26, 31,  7, 19) | 1.003 | 1.199 | 84.99 | 69.23 |##########################################| ^ (2.6%, 3.80, 2.1, 0%) 
0 >> 15/20 <<   Training | 0.8625 (24, 33,  7, 19) | 0.931 | 6.116 | 85.13 | 69.99 |-------------------------------------------------|
0             Validation | 0.8653 (24, 32,  7, 19) | 0.930 | 3.688 | 85.02 | 69.50 |#############################################| ^ (2.5%, 3.82, 3.1, 0%) 
Decay learning rate: 0.010000 -> 0.002500
0 >> 16/20 <<   Training | 0.8610 (25, 32,  7, 19) | 1.010 | 1.609 | 85.24 | 70.15 |---------------------------------------------------|
0             Validation | 0.8640 (26, 32,  7, 19) | 1.008 | 1.295 | 85.12 | 69.63 |##############################################| ^ (2.6%, 3.89, 1.2, 21%) 
Decay learning rate: 0.002500 -> 0.000625
0 >> 17/20 <<   Training | 0.8605 (26, 31,  7, 19) | 1.022 | 1.847 | 85.27 | 70.06 |--------------------------------------------------|
0             Validation | 0.8636 (26, 31,  7, 19) | 1.021 | 1.759 | 85.14 | 69.54 |#############################################| ^ (2.6%, 3.95, 1.4, 8%) 
Decay learning rate: 0.000625 -> 0.000156
0 >> 18/20 <<   Training | 0.8605 (25, 32,  7, 19) | 1.002 | 1.290 | 85.26 | 70.08 |--------------------------------------------------|
0             Validation | 0.8636 (26, 32,  7, 19) | 1.001 | 1.888 | 85.14 | 69.56 |#############################################| ^ (2.6%, 3.97, 1.3, 14%) 
Decay learning rate: 0.000156 -> 0.000039
0 >> 19/20 <<   Training | 0.8605 (25, 32,  7, 19) | 1.002 | 1.065 | 85.26 | 70.07 |--------------------------------------------------|
0             Validation | 0.8635 (26, 32,  7, 19) | 1.000 | 1.734 | 85.14 | 69.55 |#############################################| ^ (2.6%, 3.97, 1.4, 10%) 
Decay learning rate: 0.000039 -> 0.000010
0 >> 20/20 <<   Training | 0.8605 (25, 32,  7, 19) | 1.001 | 1.123 | 85.26 | 70.08 |--------------------------------------------------|
0             Validation | 0.8635 (26, 32,  7, 19) | 1.000 | 1.632 | 85.14 | 69.55 |#############################################| ^ (2.6%, 3.97, 1.4, 9%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_8_np1052_seed0_lr0.01_epochs20_offset0_epoch20_before_finetuning.pkl
Run Finetuning
0 >> 20/20 <<   Training | 0.8605 (25, 32,  7, 19) | 1.002 | 1.220 | 85.26 | 70.07 |--------------------------------------------------|
0             Validation | 0.8635 (26, 32,  7, 19) | 1.001 | 1.596 | 85.14 | 69.55 |#############################################| ^ (2.6%, 3.97, 1.3, 15%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_8_np1052_seed0_lr0.01_epochs20_offset0_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
