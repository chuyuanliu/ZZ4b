1 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
1 >>  1/20 <<   Training | 0.8848 (26, 29,  7, 21) | 1.072 | 5.103 | 83.51 | 68.97 |---------------------------------------|
1             Validation | 0.8846 (26, 29,  7, 21) | 1.058 | 3.698 | 83.55 | 68.95 |#######################################| ^ (1.1%, 2.93, 1.5, 5%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (1337 batches)
1 >>  2/20 <<   Training | 0.8754 (25, 32,  7, 19) | 0.956 | 1.803 | 84.04 | 68.96 |---------------------------------------|
1             Validation | 0.8756 (24, 32,  7, 19) | 0.943 | 1.091 | 84.10 | 68.83 |######################################| ^ (1.0%, 3.84, 2.2, 0%) 
1 >>  3/20 <<   Training | 0.8720 (26, 30,  7, 20) | 1.052 | 1.485 | 84.44 | 68.80 |-------------------------------------|
1             Validation | 0.8725 (26, 30,  7, 20) | 1.038 | 1.276 | 84.48 | 68.65 |####################################| ^ (0.9%, 4.55, 2.0, 0%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (668 batches)
1 >>  4/20 <<   Training | 0.8704 (26, 30,  7, 20) | 1.015 | 3.722 | 84.58 | 68.41 |----------------------------------|
1             Validation | 0.8712 (25, 30,  7, 20) | 1.002 | 3.070 | 84.64 | 68.20 |###############################| ^ (1.2%, 3.90, 1.7, 2%) 
1 >>  5/20 <<   Training | 0.8676 (25, 31,  7, 20) | 0.998 | 2.033 | 84.91 | 69.08 |----------------------------------------|
1             Validation | 0.8679 (25, 31,  7, 20) | 0.985 | 2.547 | 84.99 | 68.93 |#######################################| ^ (1.2%, 3.39, 1.7, 1%) 
1 >>  6/20 <<   Training | 0.8661 (25, 32,  7, 19) | 1.001 | 2.625 | 84.80 | 69.01 |----------------------------------------|
1             Validation | 0.8666 (25, 32,  7, 19) | 0.988 | 1.591 | 84.86 | 68.81 |######################################| ^ (1.2%, 4.19, 1.9, 1%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (334 batches)
1 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
1 >>  1/20 <<   Training | 0.8848 (26, 29,  7, 21) | 1.072 | 5.103 | 83.51 | 68.97 |---------------------------------------|
1             Validation | 0.8846 (26, 29,  7, 21) | 1.058 | 3.698 | 83.55 | 68.95 |#######################################| ^ (1.1%, 2.93, 1.5, 5%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (1337 batches)
1 >>  2/20 <<   Training | 0.8754 (25, 32,  7, 19) | 0.956 | 1.803 | 84.04 | 68.96 |---------------------------------------|
1             Validation | 0.8756 (24, 32,  7, 19) | 0.943 | 1.091 | 84.10 | 68.83 |######################################| ^ (1.0%, 3.84, 2.2, 0%) 
1 >>  3/20 <<   Training | 0.8720 (26, 30,  7, 20) | 1.052 | 1.485 | 84.44 | 68.80 |-------------------------------------|
1             Validation | 0.8725 (26, 30,  7, 20) | 1.038 | 1.276 | 84.48 | 68.65 |####################################| ^ (0.9%, 4.55, 2.0, 0%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (668 batches)
1 >> Epoch <<   Data Set |  Loss %(d4, d3, t4, t3) | Norm  | rchi2 | % AUC | % AUC | AUC Bar Graph ^ (ABC, Max Loss, chi2/bin, p-value) * Output Model
1 >>  1/20 <<   Training | 0.8848 (26, 29,  7, 21) | 1.072 | 5.103 | 83.51 | 68.97 |---------------------------------------|
1             Validation | 0.8846 (26, 29,  7, 21) | 1.058 | 3.698 | 83.55 | 68.95 |#######################################| ^ (1.1%, 2.93, 1.5, 5%) 
setGhostBatches(16)
Change training batch size: 1024 -> 2048 (1337 batches)
1 >>  2/20 <<   Training | 0.8754 (25, 32,  7, 19) | 0.956 | 1.803 | 84.04 | 68.96 |---------------------------------------|
1             Validation | 0.8756 (24, 32,  7, 19) | 0.943 | 1.091 | 84.10 | 68.83 |######################################| ^ (1.0%, 3.84, 2.2, 0%) 
1 >>  3/20 <<   Training | 0.8720 (26, 30,  7, 20) | 1.052 | 1.485 | 84.44 | 68.80 |-------------------------------------|
1             Validation | 0.8725 (26, 30,  7, 20) | 1.038 | 1.276 | 84.48 | 68.65 |####################################| ^ (0.9%, 4.55, 2.0, 0%) 
setGhostBatches(4)
Change training batch size: 2048 -> 4096 (668 batches)
1 >>  4/20 <<   Training | 0.8704 (26, 30,  7, 20) | 1.015 | 3.722 | 84.58 | 68.41 |----------------------------------|
1             Validation | 0.8712 (25, 30,  7, 20) | 1.002 | 3.070 | 84.64 | 68.20 |###############################| ^ (1.2%, 3.90, 1.7, 2%) 
1 >>  5/20 <<   Training | 0.8676 (25, 31,  7, 20) | 0.998 | 2.033 | 84.91 | 69.08 |----------------------------------------|
1             Validation | 0.8679 (25, 31,  7, 20) | 0.985 | 2.547 | 84.99 | 68.93 |#######################################| ^ (1.2%, 3.39, 1.7, 1%) 
1 >>  6/20 <<   Training | 0.8661 (25, 32,  7, 19) | 1.001 | 2.625 | 84.80 | 69.01 |----------------------------------------|
1             Validation | 0.8666 (25, 32,  7, 19) | 0.988 | 1.591 | 84.86 | 68.81 |######################################| ^ (1.2%, 4.19, 1.9, 1%) 
setGhostBatches(1)
Change training batch size: 4096 -> 8192 (334 batches)
1 >>  7/20 <<   Training | 0.8662 (26, 32,  7, 18) | 1.011 | 8.486 | 84.90 | 69.46 |--------------------------------------------|
1             Validation | 0.8669 (26, 32,  7, 18) | 0.998 | 5.283 | 84.96 | 69.21 |##########################################| ^ (1.4%, 4.35, 2.1, 0%) 
1 >>  8/20 <<   Training | 0.8646 (26, 31,  7, 19) | 1.017 | 1.104 | 84.96 | 69.55 |---------------------------------------------|
1             Validation | 0.8654 (25, 31,  7, 20) | 1.005 | 1.168 | 85.01 | 69.35 |###########################################| ^ (1.1%, 3.78, 2.4, 0%) 
1 >>  9/20 <<   Training | 0.8646 (25, 32,  7, 19) | 0.984 | 1.225 | 85.01 | 69.71 |-----------------------------------------------|
1             Validation | 0.8655 (25, 32,  7, 19) | 0.971 | 1.775 | 85.06 | 69.47 |############################################| ^ (1.5%, 4.06, 2.1, 0%) 
1 >> 10/20 <<   Training | 0.8642 (25, 32,  7, 19) | 0.977 | 1.081 | 84.90 | 69.34 |-------------------------------------------|
1             Validation | 0.8648 (25, 32,  7, 19) | 0.965 | 1.209 | 84.96 | 69.18 |#########################################| ^ (1.2%, 4.24, 1.7, 2%) 
setGhostBatches(0)
Change training batch size: 8192 -> 16384 (167 batches)
1 >> 11/20 <<   Training | 0.8635 (25, 33,  7, 18) | 0.984 | 2.846 | 85.05 | 69.59 |---------------------------------------------|
1             Validation | 0.8645 (25, 33,  7, 18) | 0.971 | 2.522 | 85.09 | 69.33 |###########################################| ^ (1.4%, 4.55, 1.9, 1%) 
1 >> 12/20 <<   Training | 0.8646 (27, 32,  7, 18) | 1.043 | 3.506 | 85.09 | 69.61 |----------------------------------------------|
1             Validation | 0.8655 (26, 32,  7, 18) | 1.030 | 2.445 | 85.14 | 69.36 |###########################################| ^ (1.3%, 4.52, 2.4, 0%) 
1 >> 13/20 <<   Training | 0.8630 (26, 31,  7, 19) | 1.057 | 3.284 | 85.06 | 69.59 |---------------------------------------------|
1             Validation | 0.8639 (26, 31,  7, 19) | 1.043 | 1.803 | 85.12 | 69.31 |###########################################| ^ (1.5%, 4.29, 2.0, 0%) 
1 >> 14/20 <<   Training | 0.8628 (26, 31,  7, 19) | 1.033 | 1.277 | 85.10 | 69.78 |-----------------------------------------------|
1             Validation | 0.8639 (26, 31,  7, 19) | 1.019 | 1.679 | 85.16 | 69.48 |############################################| ^ (1.6%, 4.22, 2.0, 0%) 
1 >> 15/20 <<   Training | 0.8632 (25, 33,  7, 18) | 0.964 | 3.746 | 85.05 | 69.77 |-----------------------------------------------|
1             Validation | 0.8643 (25, 33,  7, 18) | 0.951 | 2.694 | 85.09 | 69.52 |#############################################| ^ (1.4%, 4.51, 1.7, 2%) 
Decay learning rate: 0.010000 -> 0.002500
1 >> 16/20 <<   Training | 0.8619 (25, 32,  7, 19) | 0.973 | 1.815 | 85.13 | 70.08 |--------------------------------------------------|
1             Validation | 0.8632 (25, 32,  7, 19) | 0.960 | 1.813 | 85.18 | 69.79 |###############################################| ^ (1.5%, 4.71, 2.4, 0%) 
Decay learning rate: 0.002500 -> 0.000625
1 >> 17/20 <<   Training | 0.8615 (26, 31,  7, 19) | 1.023 | 1.008 | 85.17 | 69.89 |------------------------------------------------|
1             Validation | 0.8626 (26, 32,  7, 19) | 1.010 | 1.032 | 85.22 | 69.59 |#############################################| ^ (1.6%, 4.71, 2.0, 0%) 
Decay learning rate: 0.000625 -> 0.000156
1 >> 18/20 <<   Training | 0.8614 (25, 32,  7, 19) | 1.001 | 1.045 | 85.17 | 69.93 |-------------------------------------------------|
1             Validation | 0.8626 (25, 32,  7, 19) | 0.988 | 1.080 | 85.22 | 69.63 |##############################################| ^ (1.6%, 4.70, 2.0, 0%) 
Decay learning rate: 0.000156 -> 0.000039
1 >> 19/20 <<   Training | 0.8614 (25, 32,  7, 19) | 1.002 | 1.226 | 85.17 | 69.92 |-------------------------------------------------|
1             Validation | 0.8626 (25, 32,  7, 19) | 0.989 | 1.195 | 85.22 | 69.62 |##############################################| ^ (1.6%, 4.70, 2.0, 0%) 
Decay learning rate: 0.000039 -> 0.000010
1 >> 20/20 <<   Training | 0.8614 (25, 32,  7, 19) | 1.002 | 1.085 | 85.17 | 69.92 |-------------------------------------------------|
1             Validation | 0.8626 (25, 32,  7, 19) | 0.989 | 1.266 | 85.22 | 69.62 |##############################################| ^ (1.6%, 4.69, 2.0, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_8_np1052_seed0_lr0.01_epochs20_offset1_epoch20_before_finetuning.pkl
Run Finetuning
1 >> 20/20 <<   Training | 0.8614 (25, 32,  7, 19) | 1.003 | 1.216 | 85.17 | 69.91 |-------------------------------------------------|
1             Validation | 0.8626 (25, 32,  7, 19) | 0.990 | 1.174 | 85.22 | 69.61 |##############################################| ^ (1.6%, 4.69, 1.9, 0%) * ZZ4b/nTupleAnalysis/pytorchModels/FvT_HCR+attention_8_np1052_seed0_lr0.01_epochs20_offset1_epoch20.pkl
Decay learning rate: 0.000010 -> 0.000002
